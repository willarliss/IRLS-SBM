{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c5fbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.estimate import sbm_slow, sbm_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd8019",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "# probs = np.array([\n",
    "#     [0.9, 0.01, 0.01],\n",
    "#     [0.01, 0.9, 0.01],\n",
    "#     [0.01, 0.01, 0.9],\n",
    "# ])\n",
    "# probs = np.array([\n",
    "#     [0.9, 0.9, 0.9],\n",
    "#     [0.9, 0.9, 0.9],\n",
    "#     [0.9, 0.9, 0.9],\n",
    "# ])\n",
    "probs = np.array([\n",
    "    [0.4, 0.01, 0.01],\n",
    "    [0.01, 0.4, 0.01],\n",
    "    [0.01, 0.01, 0.4],\n",
    "])\n",
    "# probs = np.array([\n",
    "#     [0.1, 0.0, 0.0],\n",
    "#     [0.0, 0.1, 0.0],\n",
    "#     [0.0, 0.0, 0.1],\n",
    "# ])\n",
    "# probs = np.array([\n",
    "#     [0.4, 0.4, 0.01],\n",
    "#     [0.4, 0., 0.01],\n",
    "#     [0.01, 0.01, 0.42],\n",
    "# ])\n",
    "# sizes = rng.poisson(111, size=3)\n",
    "# sizes = rng.poisson(555, size=3)\n",
    "sizes = rng.poisson(1111, size=3)\n",
    "graph = nx.stochastic_block_model(sizes, probs, seed=rng)\n",
    "labels = [b for n, b in graph.nodes(data='block')]\n",
    "num = sizes.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa94ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src import estimate\n",
    "# estimate.VERBOSE = False\n",
    "# %load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b63e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit sbm_slow(graph, 3, max_iter=100, tol=0)\n",
    "# %memit sbm_slow(graph, 3, max_iter=100, tol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981e8ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit sbm_fast(graph, 33, max_iter=100, tol=0, alpha=0.1)\n",
    "# %timeit sbm_fast(graph, 3, max_iter=100, tol=0)\n",
    "# %memit sbm_fast(graph, 3, max_iter=100, tol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabf007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(0)\n",
    "# seed = 123\n",
    "# np.random.seed(seed)\n",
    "# p1, t1 = sbm_slow(graph, 3, max_iter=100, track_scores=True, tol=0.)\n",
    "# np.random.seed(seed)\n",
    "# p2, t2 = sbm_fast(graph, 3, max_iter=100, track_scores=True, tol=0.)\n",
    "# np.abs(p1-p2).mean(), np.abs(t1-t2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40efa06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = sbm_fast(graph, 3, alpha=0.25, tol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dafa45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab796cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, scores = sbm_fast(graph, 3, alpha=0.01, tol=0.01, track_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6a4768",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b05c75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38c0509d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70491d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.estimate import *\n",
    "\n",
    "# This approach implements the method with more computational efficiency\n",
    "def sbm_fast(G, k, *,\n",
    "             likelihood='bernoulli',\n",
    "             alpha=0.,\n",
    "             weight=None,\n",
    "             track_scores=False,\n",
    "             max_iter=100,\n",
    "             min_epochs=10,\n",
    "             tol=0.01):\n",
    "\n",
    "    track_scores = True\n",
    "\n",
    "    ## Adjacency matrix ##\n",
    "    A = nx.to_scipy_sparse_array(G, weight=weight).astype(float)\n",
    "    A_dense = A.toarray() if track_scores else None\n",
    "    n_nodes = len(G.nodes)\n",
    "\n",
    "    if likelihood == 'bernoulli':\n",
    "        assert ((A.data==0) | (A.data==1)).all()\n",
    "    elif likelihood == 'poisson':\n",
    "        assert (A.data >= 0).all() and (A.data == A.data.round()).all()\n",
    "    elif likelihood == 'normal':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    ## Soft partition matrix ##\n",
    "    X = np.ones((n_nodes, k)) / k\n",
    "    X += np.random.randn(n_nodes, k) / 100\n",
    "    ## Hard partition matrix ##\n",
    "    partition = X.argmax(1)\n",
    "    Z = csr_array((np.ones(n_nodes), (np.arange(n_nodes), partition)),\n",
    "                  shape=X.shape, dtype=X.dtype)\n",
    "\n",
    "    ## Structure matrix sufficient statistics ##\n",
    "    M = Z.T @ (A @ Z)\n",
    "    n = Z.sum(0)[:, None]\n",
    "    ## Structure matrix MLE ##\n",
    "    B = M.toarray() / (n@n.T).clip(1, None)\n",
    "\n",
    "    ## Regularization ##\n",
    "    R = np.eye(k) * alpha\n",
    "\n",
    "    if track_scores:\n",
    "        vprint('tracking scores may significantly increase runtime')\n",
    "        ## Initialize trace of scores ##\n",
    "        P = np.clip(Z@B@Z.T, EPS, 1-EPS)\n",
    "        if likelihood == 'bernoulli':\n",
    "            L = A_dense * np.log(P) + (1-A_dense) * np.log(1-P)\n",
    "        elif likelihood == 'poisson':\n",
    "            L = A_dense * np.log(P) - P\n",
    "        elif likelihood == 'normal':\n",
    "            L = 1/2 * (A_dense - P)**2\n",
    "        trace = [L.mean()]\n",
    "\n",
    "    history = []\n",
    "    history.append((X.copy(), Z.toarray().copy(), L.mean()))\n",
    "\n",
    "    for epoch in range(max_iter):\n",
    "\n",
    "        ## Compute predictions ##\n",
    "        if likelihood == 'bernoulli':\n",
    "            w_pre = 1 / (B * (1 - B)).clip(EPS, None)\n",
    "        elif likelihood == 'poisson':\n",
    "            w_pre = 1 / B.clip(EPS, None)\n",
    "        elif likelihood == 'normal':\n",
    "            w_pre = np.ones_like(B)\n",
    "        w_block = (w_pre * n.T).sum(axis=1) / n.sum()\n",
    "        w = w_block[partition]\n",
    "\n",
    "        ## Perform fisher scoring updates ##\n",
    "        # ZB = B.T[partition, :]\n",
    "        ZB = Z @ B.T\n",
    "        ZBW = ZB * w[:, None]\n",
    "        hess = ZB.T @ ZBW + R\n",
    "        # grad = ZBW.T @ A\n",
    "        grad = (A.T @ ZBW).T\n",
    "        X = (X - Z) + np.linalg.solve(hess, grad).T\n",
    "\n",
    "        ## Update partition ##\n",
    "        prev_partition = partition\n",
    "        partition = X.argmax(1)\n",
    "\n",
    "        ## Recompute structure matrix ##\n",
    "        Z.indices[:], Z.data[:] = partition, 1\n",
    "        # Z.indices[:] = partition\n",
    "        # Z.data[:] = 1\n",
    "        M = Z.T @ (A @ Z)\n",
    "        n = Z.sum(0)[:, None]\n",
    "        B = M.toarray() / (n@n.T).clip(1, None)\n",
    "\n",
    "        ## Early stopping ##\n",
    "        if epoch > min_epochs and (prev_partition == partition).mean() > 1-tol:\n",
    "            vprint('converged in', epoch+1, 'iterations')\n",
    "            break\n",
    "\n",
    "        ## Append current score to trace ##\n",
    "        if track_scores:\n",
    "            P = np.clip(Z@B@Z.T, EPS, 1-EPS)\n",
    "            if likelihood == 'bernoulli':\n",
    "                L = A_dense * np.log(P) + (1-A_dense) * np.log(1-P)\n",
    "            elif likelihood == 'poisson':\n",
    "                L = A_dense * np.log(P) - P\n",
    "            elif likelihood == 'normal':\n",
    "                L = 1/2 * (A_dense - P)**2\n",
    "            trace.append(L.mean())\n",
    "        history.append((X.copy(), Z.toarray().copy(), L.mean()))\n",
    "\n",
    "    else:\n",
    "        vprint('did not converge after', max_iter, 'iterations')\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a9322",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "# probs = np.array([\n",
    "#     [0.25, 0.001, 0.001],\n",
    "#     [0.001, 0.25, 0.001],\n",
    "#     [0.001, 0.001, 0.25],\n",
    "# ])\n",
    "probs = np.array([\n",
    "    [0.4, 0.01, 0.01],\n",
    "    [0.01, 0.4, 0.01],\n",
    "    [0.01, 0.01, 0.4],\n",
    "])\n",
    "sizes = rng.poisson(111, size=3)\n",
    "graph = nx.stochastic_block_model(sizes, probs, seed=rng)\n",
    "labels = [b for n, b in graph.nodes(data='block')]\n",
    "num = sizes.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e371c94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = sbm_fast(graph, 3, max_iter=20, alpha=0.01, tol=0.0)\n",
    "history[-1][0].argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hist = [h[0] for h in history]\n",
    "Z_hist = [h[1] for h in history]\n",
    "scores = [h[2] for h in history]\n",
    "smin, smax = min(scores), max(scores)\n",
    "srange = smax-smin\n",
    "smin, smax = smin-(smax-smin)/10, smax+(smax-smin)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d398b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT:\n",
    "\n",
    "from IPython.display import Image as IPImage\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from IPython.display import clear_output, display\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Required variables from previous cells: X_hist, Z_hist, scores, graph\n",
    "n_steps = len(X_hist)\n",
    "\n",
    "# fixed layout for reproducibility; compute once\n",
    "pos = nx.spring_layout(graph, seed=0)\n",
    "\n",
    "# collect frames (RGB uint8 arrays)\n",
    "frames = []\n",
    "\n",
    "# single updating display using clear_output so only one figure is shown\n",
    "for i in range(n_steps):\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "    gs = fig.add_gridspec(2, 3, width_ratios=[1, 1, 1.2], height_ratios=[1, 1], hspace=0.35)\n",
    "\n",
    "    # Left: top row has X and Z side-by-side\n",
    "    ax_X = fig.add_subplot(gs[0, 0])\n",
    "    ax_Y = fig.add_subplot(gs[0, 1])\n",
    "    # Right: graph spans both rows\n",
    "    ax_graph = fig.add_subplot(gs[:, 2])\n",
    "    # Bottom: scores span left two columns\n",
    "    ax_score = fig.add_subplot(gs[1, 0:2])\n",
    "\n",
    "    # X and Z images for this step\n",
    "    ax_X.imshow(X_hist[i], aspect='auto')\n",
    "    ax_X.set_title('Latent variable $X$')\n",
    "    ax_X.set_xticks([])\n",
    "\n",
    "    ax_Y.imshow(Z_hist[i], aspect='auto', interpolation='none')\n",
    "    ax_Y.set_title('Partition $Z$')\n",
    "    ax_Y.set_xticks([])\n",
    "\n",
    "    # Scores up to this step\n",
    "    xs = np.arange(i + 1)\n",
    "    ys = np.array(scores[: i + 1])\n",
    "    ax_score.plot(xs, ys, color='C1')\n",
    "    ax_score.set_xlim(0, max(1, n_steps - 1))\n",
    "    ax_score.set_ylim([smin, smax])\n",
    "    ax_score.set_ylabel('Log-likelihood $\\propto$')\n",
    "    ax_score.set_xlabel('Iteration')\n",
    "\n",
    "    # Graph colored by partition at this step\n",
    "    partition = np.array(Z_hist[i]).argmax(1)\n",
    "    nx.draw(graph, pos=pos, node_color=partition, cmap='tab10', ax=ax_graph, with_labels=False, node_size=80)\n",
    "\n",
    "    # draw and capture frame\n",
    "    fig.canvas.draw()\n",
    "    w, h = fig.canvas.get_width_height()\n",
    "    img = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8').reshape((h, w, 3))\n",
    "    frames.append(img)\n",
    "\n",
    "    # show only the latest figure in the notebook output\n",
    "    # clear_output(wait=True)\n",
    "    # display(fig)\n",
    "    # plt.pause(0.05)\n",
    "    plt.close(fig)\n",
    "\n",
    "# after loop, write gif to disk if possible\n",
    "out_path = 'sbm_animation.gif'\n",
    "imgs = [Image.fromarray(f) for f in frames]\n",
    "imgs[0].save(out_path, save_all=True, append_images=imgs[1:], duration=200, loop=0)\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(IPImage(filename=out_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7749da29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
